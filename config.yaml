api:
  host: "0.0.0.0"
  port: 8000
  debug: true

providers:
  default: "openai"  # Which provider to use by default
  
  openai:
    enabled: true
    models:
      default: "gpt-4-turbo-preview"
      allowed:
        - "gpt-4-turbo-preview"
        - "gpt-4"
        - "gpt-3.5-turbo"
    max_tokens: 2048
    
  anthropic:
    enabled: true
    models:
      default: "claude-3-opus-20240229"
      allowed:
        - "claude-3-opus-20240229"
        - "claude-3-sonnet-20240229"
        - "claude-2.1"
    max_tokens: 2048
    
  ollama:
    enabled: true
    host: "http://localhost:11434"
    models:
      default: "llama2"
      allowed:
        - "llama2"
        - "mistral"
        - "mixtral"
    max_tokens: 2048

search:
  google:
    enabled: true
    results_per_query: 10

logging:
  version: 1
  disable_existing_loggers: false
  
  formatters:
    detailed:
      format: "%(asctime)s.%(msecs)03d|%(session_id)s|%(filename)s:%(lineno)d|%(levelname)s|%(message)s"
      datefmt: "%Y-%m-%d %H:%M:%S"
  
  filters:
    session_filter:
      (): logging_config.SessionFilter
  
  handlers:
    console:
      class: logging.StreamHandler
      level: DEBUG
      formatter: detailed
      filters: [session_filter]
      stream: ext://sys.stdout
    
    file:
      class: logging.handlers.RotatingFileHandler
      level: DEBUG
      formatter: detailed
      filters: [session_filter]
      filename: logs/search_agent.log
      maxBytes: 10485760  # 10MB
      backupCount: 5
      encoding: utf8
  
  loggers:
    search_agent:
      level: DEBUG
      handlers: [console, file]
      propagate: false
    
    uvicorn:
      level: INFO
      handlers: [console, file]
      propagate: false
  
  root:
    level: DEBUG
    handlers: [console, file]